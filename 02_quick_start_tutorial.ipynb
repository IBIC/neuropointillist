{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuropointillist quick start tutorial \n",
    "\n",
    "Adapted from http://ibic.github.io/neuropointillist/ and http://ibic.github.io/neuropointillist/usage.html\n",
    "\n",
    "In this tutorial, we will use the provided example.rawfmri dataset and files to run neuropointillist. \n",
    "\n",
    "While the neuropointillist code is mostly in R, you will interact with its functions through the Terminal using bash. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding neuropointillist to your path\n",
    "\n",
    "Open up Terminal and run the below code, replacing *path_to_repo* with whatever folder you cloned the neuropointillist repository into. This adds the neuropointillist repository to your path so that you can use its functions anywhere. \n",
    "\n",
    "    export PATH=$PATH:path_to_repo/neuropointillist\n",
    "\n",
    "Note that this should be the path to the main neuropointillist folder, which will itself contain a neuropointillist folder. For example, if your folders look like ~/Desktop/neuropointillist/neuropointillist, you would replace *path_to_repo* with ~/Desktop\n",
    "\n",
    "If you are already in the folder containing the neuropointillist repository (in the above example, you would be in ~/Desktop), you can run the following to set up your path: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PATH=$PATH:`pwd`/neuropointillist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to permanently add neuropointillist to your path so that you don't have to do the above step every time you open a new Terminal, you can add the neuropointillist path to your ~/.bashrc or ~/.bash_profile (make sure you use the full path for this, NOT the pwd trick!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### npoint function\n",
    "The function npoint prepares the fMRI data for modeling.\n",
    "\n",
    "Below is the command line syntax to run npoint:\n",
    "\n",
    "npoint --set1 listoffiles1.txt --setlabels1 file1.csv --set2 listoffiles2.txt --setlabels2 file2.csv --covariates covariatefile.csv --mask mask.nii.gz --model code.R [ -p N | --sgeN N] --output output --debugfile outputfile\n",
    "\n",
    "Let's go through what each input means. If you want to skip this for now and just run the tutorial, skip ahead to **Using readargs.R with npoint function**. \n",
    "\n",
    "* --set1 (through up to set5)\n",
    "    * corresponds to paths/filenames for your input niftis\n",
    "    * for longitudinal data, each set can correspond to a time point (e.g. set1 is timepoint 1, set2 is timepoint 2), but you don't have to do this. You can also put everyone in a single set with timepoint as a covariate. \n",
    "    * If you have multiple sets, they do not have to have the same set of participants (i.e. missing data is okay if your model supports that)\n",
    "    * if you need more than five input sets, you can have everyone in one set with corresponding covariates (e.g. include timepoint as a covariate)\n",
    "    \n",
    "    \n",
    "* --setlabels1 (through up to setlabels5)\n",
    "    * csv files with labels for the niftis in your set\n",
    "    * the number of setlabels files must match the number of set files\n",
    "    * if the MRI data files in each set are 3D, the list of files in the set should have exactly the same number of entries as the corresponding setlabels file. This normally includes\n",
    "        * participant ID\n",
    "        * longitudinal timepoint\n",
    "    * for fMRI data (4D data), each row of your csv is a volume (TR) with labels for stuff, including the regressors that you'll later include in your mixed model. \"Stuff\" will normally include:\n",
    "        * participant ID\n",
    "        * longitudinal timepoint\n",
    "        * TR number\n",
    "        * elements of your design matrix (regressors of interest)\n",
    "    * the data in setlabels must be in the same order as the data in the set files\n",
    "    * the headers of the setlabels files must be consistent across sets and consistent with headers in the covariate file (below; if specified)\n",
    "    * Note that in the quick start tutorial, High and Low are two contrast regressors (1 or 0) convolved with an HRF\n",
    "    \n",
    "    Below is an example of what your fMRI setlabels file could look like, where ... represents TRs not shown:\n",
    "    \n",
    "| Regressor1 | Regressor2 | ParticipantID | TR  | LongTimepoint |\n",
    "|------------|------------|---------------|-----|------------------------|\n",
    "| 1          | 0          | 1             | 1   | 1                      |\n",
    "| 1          | 0          | 1             | 2   | 1                      |\n",
    "| 0          | 1          | 1             | 3   | 1                      |\n",
    "| ...        | ...        | ...           | ... | ...                    |\n",
    "| 1          | 0          | 1             | 150 | 1                      |\n",
    "| 1          | 0          | 2             | 1   | 1                      |\n",
    "| 1          | 0          | 2             | 2   | 1                      |\n",
    "| 0          | 1          | 2             | 3   | 1                      |\n",
    "| ...        | ...        | ...           | ... | ...                    |\n",
    "    \n",
    "* --covariates\n",
    "    * a csv file that associates participant IDs with any number of covariates (e.g. age, IQ, etc.)\n",
    "    * all of the information in covariates can, instead, be specified in setlabels; the covariates tag is a convenience option\n",
    "    * if a covariate file is specified, it will be merged with the content of the setlabels files based on the header fields that are common to both. An error will occur if there are no common header fields.\n",
    "    \n",
    "    Below is an example of a covariates file that would work with the above example setlabels file.\n",
    "    \n",
    "| ParticipantID | LongTimepoint | age | IQ  |\n",
    "|---------------|-----------|-----|-----|\n",
    "| 1             | 1         | 8   | 100 |\n",
    "| 2             | 1         | 8   | 110 |\n",
    "| 3             | 1         | 8   | 90  |\n",
    "| 1             | 2         | 10  | 100 |\n",
    "| ...           | ...       | ...  | ... |\n",
    "\n",
    "\n",
    "* --mask\n",
    "    * a nifti file of 1s and 0s, so that computation will be limited to voxels set to 1 (i.e. only run model in brain voxels; don't waste time running model in voxels outside of the brain)\n",
    "    * must be the same type and size as the first three dimensions of all set inputs (e.g. same size as your input niftis)\n",
    "\n",
    "\n",
    "* --model\n",
    "    * an R file that specifies the R template code to run your model and return results\n",
    "    * can also include any initialization code (e.g. included libraries)\n",
    "    * must define the function processVoxel(v), which is described further down\n",
    "\n",
    "\n",
    "* -p N\n",
    "    * specifies that multicore parallelism will be implemented using N processors. \n",
    "    * A warning is given if the number of processors specified exceeds the number of cores. See SECTION on running a model using multicore parallelism.\n",
    "    \n",
    "    \n",
    "* --sgeN N \n",
    "    * specifies to read the data and divide it into N jobs that can be submitted to the SGE (using a runme.sge script that npoint generates) or divided among machines by hand and run using GNU make. \n",
    "    * if SGE parallelism is used, assumes that the directory that the program is called from is read/writeable from all cluster nodes. See SECTION on running a model using SGE parallelism.\n",
    "    \n",
    "    \n",
    "* --output outputprefix\n",
    "    * specify the prefix that is prepended to output files to facilitate organization\n",
    "    * e.g. using --output model-ageXtime/model1 will organize all output files and scripts to a subdirectory called model-ageXtime, and it will prepend model1 to your output files\n",
    "    * the model and calling arguments will be copied with this output prefix so that you have a record of what you ran\n",
    "\n",
    "\n",
    "* --debug debugfile \n",
    "    * writes out external representations of the design matrix, the fMRI data, and a function called imagecoordtovertex, which maps three-dimensional image coordinates (e.g. from fslview) into a vertex number, to the file debugfile.R. T\n",
    "    * useful for development and testing of your model, or troubleshooting problems with the setfiles or covariate files. See the Vignette for instructions for how to use the debugfile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using readargs.R with npoint function\n",
    "\n",
    "If you don't want to type all the arguments for npoint function, you can use the R file readargs.R to set a vector called cmdargs that contains the arguments. \n",
    "\n",
    "Below is the example readargs.R file from the quick start tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cmdargs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0432c47ac5e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m cmdargs <- c(\"-m\",\"mask_4mm.nii.gz\", \"--set1\", \"setfilenames1.txt\",\n\u001b[0m\u001b[1;32m      2\u001b[0m              \u001b[0;34m\"--set2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"setfilenames2.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m              \u001b[0;34m\"--setlabels1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"setlabels1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0;34m\"--setlabels2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"setlabels2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0;34m\"--model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmrimodel.R\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cmdargs' is not defined"
     ]
    }
   ],
   "source": [
    "cmdargs <- c(\"-m\",\"mask_4mm.nii.gz\", \"--set1\", \"setfilenames1.txt\",\n",
    "             \"--set2\", \"setfilenames2.txt\",             \n",
    "             \"--setlabels1\", \"setlabels1.csv\",\n",
    "             \"--setlabels2\", \"setlabels2.csv\",             \n",
    "             \"--model\", \"fmrimodel.R\",\n",
    "             \"--output\", \"sgedata/sim.\",\n",
    "             \"--debug\", \"debug.Rdata\",\n",
    "             \"--sgeN\", \"10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running npoint function\n",
    "\n",
    "To continue with the tutorial (remember that we're in Terminal), enter the neuropointillist/example.rawfmri folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_detailed_install.ipynb\n",
      "02_quick_start_tutorial.ipynb\n",
      "LICENSE\n",
      "NPointTutorial.ipynb\n",
      "README.html\n",
      "README.md\n",
      "docs\n",
      "example.flournoy\n",
      "example.lavaan\n",
      "example.rawfmri\n",
      "flowchart.pptx\n",
      "neuropointillist\n",
      "npoint\n",
      "npointillist-chart.odg\n",
      "npointillist_chart.pdf\n",
      "npointmerge\n",
      "npointrun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: cd: neuropointillist/example.rawfmri/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "cd neuropointillist/example.rawfmri/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this folder, run npoint to prepare your fMRI data for modeling. Because there is a readargs.R function prepared, we do not need to type all the arguments into the command line, just the command npoint: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate a folder called sgedata (remember this is named that way because we set --output to sgedata/sim.)\n",
    "\n",
    "Enter this folder and check its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd sgedata\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used -p N or --sge N, the npoint function will split your brain mask into N chunks so that each processor can run its own chunk of brain in parallel. For example, if you set N to 2, your brain would be divided in half so that each half can be processed separately in parallel.\n",
    "\n",
    "Because we used --output sgedata/sim. for the quick start tutorial, your chunks will be named sim.0001, sim.0002, up to the N you specified for parallelizing the analysis.\n",
    "* sim.####.nii.gz files are the \"chunks\" of brain mask, with 1s for that chunk of brain and 0s for the rest of the space.\n",
    "* sim.####.rds files are giant r matrixes with voxel data for all subs for the corresponding chunk of brain. \n",
    "\n",
    "Makefile is a make file that is called by the runme files. It calls the functions npointrun and npointmerge.\n",
    "* npointrun runs your specified model (in fmrimodel.R) through every voxel of your data in each of your brain chunks. This may take a while!\n",
    "* npointmerge merges the npointrun output, spread across multiple brain chunks, back into a single brain\n",
    "\n",
    "Run neuropointillist using either runme.local (locally) or runme.sge (over an sge cluster).\n",
    "\n",
    "You may have to first change the permissions for the runme files. The below example will use runme.local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#give yourself execute permisssions\n",
    "chmod +x ./runme.local\n",
    "./runme.local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once npoint is finally done running (this may take multiple hours?), your sgedata folder will have new model output niftis named \n",
    "* sim.p-High.gt.Low.nii.gz\n",
    "* sim.tstat-High.gt.Low.nii.gz\n",
    "* sim.tstat-High.nii.gz\n",
    "* sim.tstat-Low.nii.gz\n",
    "\n",
    "Congratulations! You have completed the quick start tutorial!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
